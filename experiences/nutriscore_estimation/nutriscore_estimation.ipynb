{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Purpose of this notebook**\n",
    "- [X] to be a tutorial of simple machine learning tools\n",
    "- [X] first contact with machine learning and/or openfoodfacts data\n",
    "\n",
    "It is proposed to estimate the `nutriscore` thanks to the machine learning as a tutorial. In this journey, we're going to share some key practices to build a machine learning model.\n",
    "\n",
    "**What are in this notebook**\n",
    "- [ ] look at the product data\n",
    "- [ ] manipulate simple machine learning tools\n",
    "- [ ] estimate nutriscore and evaluate one model\n",
    "\n",
    "**WARNING**: you will need to install some packages. Prepare a specific virtual environment is recommanded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # to install basic packages\n",
    "# # numpy: numeric python package. The basic of array manipulation\n",
    "# # pandas: based on R DataFrame. Helper to manipulate table data\n",
    "# # scikit-learn: the scientific kit for \"classic\" and basic machine learning\n",
    "# # tqdm: to see progress bar\n",
    "# !pip install -U scikit-learn matplotlib numpy pandas tqdm missingno"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook was developped with specific relative path regarding the data. If your data repository is elsewhere or the files have different, change the command in the notebook accordingly. Ask or look for help if you struggle."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data of openfoodfacts. This data was extracted from the [dump Mongo DB available](https://fr.openfoodfacts.org/data). Only some fields of the documents were retrieved, particularly the ingredients and the evaluation score such as nutriscore, ecoscore and nova group.\n",
    "\n",
    "The data is a list of dict saved as a JSON text file. Each element of of the list is a product and the key-value pairs are the information of the product."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "DATA_PATH = Path('../../data').resolve() # resolve from Path get the real absolute path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open a file with `with` in `r` (reading mode) avoid to close it explicitly\n",
    "with open(DATA_PATH / 'products.json', 'r') as file: \n",
    "    data = json.load(file)\n",
    "    \n",
    "# you can also read the csv file with this following command\n",
    "# from pandas import DataFrame, read_csv\n",
    "# df = read_csv(DATA_PATH / 'products.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0].keys()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## select/calculate relevant features of our products link to nutriscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame, Series\n",
    "from tqdm import tqdm\n",
    "from typing import Dict, Any, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_name(code: str, data:Dict[str, Any])-> str:\n",
    "    \"\"\"return the name of the product\"\"\"\n",
    "    return [i.get('product_name') for i in data if i.get('_id') == code][0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step of every data scientist and Machine learning engineer is to filter the data correctly. In theory, if we have a lot of data, it is possible to give all of the key-value as data and let the model select itself the key-values or features that provide predictive power. Be smart!! Save time, energy and money!!\n",
    "\n",
    "We want to estimate the nutriscore. The nutriscore is evaluate from the nutrition caracteristics of the food. Let's use the nutriment data of the products.\n",
    "\n",
    "It is possible also to calculate features from raw data if they seems to be more relevant. For instance, it is very common to use Fast Fourier Transform (FFT) coefficients to treat sound data or vibration.\n",
    "\n",
    "**Warning**: sometimes it is obvious which features is related to the target (here nutriscore), sometimes not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each products, select the nutriment data for 100g and 100ml\n",
    "# by chance, each product has the information for one portion.\n",
    "# if not, it should be calculated as it helps to compare products\n",
    "\n",
    "# by standard notation, X is features and y is target/label\n",
    "# I use X_ and y_ because they are temporary files to build table/array data.\n",
    "X_, y_ = {}, {} \n",
    "for product in tqdm(data):\n",
    "    X_[product['_id']] = {k:v for k, v in product['nutriments'].items() if '_100g' in k or '_100ml' in k}\n",
    "    y_[product['_id']] = product['nutriscore_grade']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = DataFrame.from_dict(X_, orient='index')\n",
    "y = Series(y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(X.head(5))\n",
    "display(X.tail(5))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems there is a lot of Not a Number (NaN). Let's look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = '5414972123165'\n",
    "print(get_name(code, data))\n",
    "X.loc[code].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import missingno as msno\n",
    "\n",
    "msno.matrix(X);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop everycolumns with more than 20% of NaN\n",
    "perc = 20.0 # Like N %\n",
    "min_count =  int(((100-perc)/100)*X.shape[0] + 1)\n",
    "msno.matrix(X.dropna( axis=1, \n",
    "                thresh=min_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(X['nutrition-score-fr_100g'], y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Something is weird with the nutrition score, because it goes from -10 to 30 for every category."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The information is here. By convenience, put every NaN to a value, here 0.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.dropna(axis=1, thresh=min_count)\n",
    "X.drop(columns='nutrition-score-fr_100g')\n",
    "X = X.fillna(0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some steps before to try and train a model:\n",
    "- **split my data** into a train and a test set. It is unthinkable to evaluate the model on data that are used for training. For explaination, look for `data leaking` on internet.\n",
    "- **set a scaler** to help the model to correlate the variation of feature with the variation of the target more easily. Very impacting for kind of model such as linear one.\n",
    "- **set a label encoder for target** because it is easier to manipulate figure than text for machine learning tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# build and set the label encoder\n",
    "# it exists other encoder such as one hot encoder. But luckily here, there is a ranking, a hierarchy between the target value.\n",
    "# A is good when e is very bad.\n",
    "# LabelEncoder fit this kind of label very well.\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    stratify=y,\n",
    "    random_state=42,\n",
    "    train_size=0.7,\n",
    "    )\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train); # never fit the scaler on all data, but only on train otherwise the sky will fall on you!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{X_train.shape=}')\n",
    "print(f'{y_train.shape=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = sorted(y.unique())\n",
    "for i, j in zip(tmp, encoder.transform(tmp)):\n",
    "    print(i,':', j)\n",
    "del tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# warning: the output of sklearn preprocessor is numpy array\n",
    "print('X_train:', type(scaler.transform(X_train)))\n",
    "print('y_train:', type(encoder.transform(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(X_train.iloc[0])\n",
    "display(scaler.transform(X_train)[:, 0]) # the value change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 2)\n",
    "\n",
    "X_train.iloc[0:10, 0:10].boxplot(rot=90, ax=axes[0])\n",
    "\n",
    "axes[0].set_title('original')\n",
    "axes[1].set_title('After scaler')\n",
    "\n",
    "DataFrame(\n",
    "    data=scaler.transform(X_train)[0:10, 0:10],\n",
    "    columns=X_train.columns[0:10],\n",
    "    index=X_train.index[0:10]\n",
    ").boxplot(rot=90, ax=axes[1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and evaluate our model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Good tips**:  \n",
    "- If possible, try small and fast, and complexify your experimentation.\n",
    "- Why not to train on small datasets and verify if it works at > 80%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(max_iter=10_000)\n",
    "model.fit(\n",
    "    scaler.transform(X_train.iloc[0:500]),\n",
    "    encoder.transform(y_train.iloc[0:500])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on itself\n",
    "y_pred_500 = model.predict(scaler.transform(X_train.iloc[0:500]))\n",
    "# on unseen data\n",
    "y_pred_1000 = model.predict(scaler.transform(X_train.iloc[500:1000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    balanced_accuracy_score,\n",
    "    confusion_matrix,\n",
    "    multilabel_confusion_matrix\n",
    ")\n",
    "\n",
    "first_test = balanced_accuracy_score(\n",
    "    y_true=encoder.transform(y_train.iloc[0:500]),\n",
    "    y_pred=y_pred_500\n",
    "    )\n",
    "\n",
    "second_test = balanced_accuracy_score(\n",
    "    y_true=encoder.transform(y_train.iloc[500:1000]),\n",
    "    y_pred=y_pred_1000\n",
    "    )\n",
    "\n",
    "print(f'{first_test=}')\n",
    "print(f'{second_test=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tests are very bad. Even on training dataset on which the model was trained, the result is poor.\n",
    "multilabel_confusion_matrix(\n",
    "    y_true=encoder.transform(y_train.iloc[0:500]),\n",
    "    y_pred=y_pred_500\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is there a change if we train on all the training data\n",
    "\n",
    "model = LogisticRegression(max_iter=10_000)\n",
    "model.fit(\n",
    "    scaler.transform(X_train),\n",
    "    encoder.transform(y_train)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on itself\n",
    "y_pred_train = model.predict(scaler.transform(X_train))\n",
    "# on unseen data\n",
    "y_pred_test = model.predict(scaler.transform(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_test = balanced_accuracy_score(\n",
    "    y_true=encoder.transform(y_train),\n",
    "    y_pred=y_pred_train\n",
    "    )\n",
    "\n",
    "second_test = balanced_accuracy_score(\n",
    "    y_true=encoder.transform(y_test),\n",
    "    y_pred=y_pred_test\n",
    "    )\n",
    "\n",
    "print(f'{first_test=}')\n",
    "print(f'{second_test=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Series(y_pred_test).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Series(encoder.transform(y_test)).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(\n",
    "    model,\n",
    "    X_train=X_train, X_test=X_test,\n",
    "    y_train=y_train, y_test=y_test,\n",
    "    scaler=scaler, encoder=encoder\n",
    "    ):\n",
    "    model.fit(\n",
    "        scaler.transform(X_train),\n",
    "        encoder.transform(y_train)\n",
    "        )\n",
    "    \n",
    "    # predict on itself\n",
    "    y_pred_train = model.predict(scaler.transform(X_train))\n",
    "    # on unseen data\n",
    "    y_pred_test = model.predict(scaler.transform(X_test))\n",
    "\n",
    "    evaluation_on_train = balanced_accuracy_score(\n",
    "        y_true=encoder.transform(y_train),\n",
    "        y_pred=y_pred_train\n",
    "        )\n",
    "    evaluation_on_test = balanced_accuracy_score(\n",
    "        y_true=encoder.transform(y_test),\n",
    "        y_pred=y_pred_test\n",
    "        )\n",
    "    print(f'{model=}')\n",
    "    print(f'{evaluation_on_train=}')\n",
    "    print(f'{evaluation_on_test=}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try the same approach but with other model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=500, max_depth=10)\n",
    "test_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "model = MLPClassifier(\n",
    "    hidden_layer_sizes=(512, 512, 256, 64),\n",
    "    learning_rate_init=0.001,\n",
    "    learning_rate='adaptive',\n",
    "    random_state=42,\n",
    "    max_iter=100,\n",
    "    )\n",
    "test_model(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "8fddf81331d3d403736c81a6e969efb76dc4d870870bdc04eed7585b0e0dd8d4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
